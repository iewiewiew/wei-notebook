## 集群

| 序号   | 故障类型   | 故障对象   | 用例名称                                | 执行步骤                                                                                                                                                                                                                           | 预期结果                                                                                                  | 实际结果   | 备注                                              |
|:-----|:-------|:-------|:------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------|:-------|:------------------------------------------------|
| 1    | 集群故障   | 开关机    | 验证重启集群后系统主流程功能正常                    | 1、重启集群 2、集群正常运行后，观察应用服务及中间件启动是否正常 3、验证系统主流程功能是否正常                                                                                                                                                                              | 1、集群重启成功 2、服务运行状态正常 3、系统主流程功能无异常                                                                      | nan    | nan                                             |
| 2    | 集群故障   | cpu负载高 | 模拟除master外全集群cpu使用率80%，验证系统主流程功能正常  | 1、使用chaosblade工具模拟除master外集群cpu使用率80% blade create k8s node-cpu load --names <nodeName1>,<nodeName2> --cpu-percent 80 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统主流程功能是否正常 3、销毁故障： blade destroy <uid>                | 1、故障制造成功，cpu负载高生效，可以使用top命令查看资源占用情况 top / kubectl top node 2、系统主流程验证时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功 | nan    | nan                                             |
| 3    | 集群故障   | 内存负载高  | 模拟除master外全集群内存使用率80%，验证系统主流程功能正常   | 1、使用chaosblade工具模拟除master外集群内存使用率80% blade create k8s node-mem load --names <nodeName1>,<nodeName2> --mem-percent 80 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统主流程功能是否正常 3、销毁故障： blade destroy <uid>                 | 1、故障制造成功，内存负载高生效，可以使用top命令查看资源占用情况 top / kubectl top node 2、系统主流程验证时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功  | nan    | nan                                             |
| 4    | 集群故障   | 磁盘负载高  | 模拟除master外全集群磁盘容量使用率80%，验证系统主流程功能正常 | 1、使用chaosblade工具模拟除master外集群磁盘容量使用率80% blade create k8s node-disk fill --names <nodeName1>,<nodeName2> --path /home --percent 80 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统主流程功能是否正常 3、销毁故障： blade destroy <uid>     | 1、故障制造成功，磁盘负载高生效，可以使用df命令（df -h /home）查看资源占用情况 2、系统主流程验证时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功             | nan    | nan                                             |
| 5    | 集群故障   | 网络延迟   | 模拟除master外全集群网络延迟50毫秒，验证系统主流程功能正常   | 1、使用chaosblade工具模拟除master外集群网络延迟50毫秒 blade create k8s node-network delay --names <nodeName1>,<nodeName2> --interface eth0 --time 50  --timeout 600 --kubeconfig /root/.kube/config 2、验证系统主流程功能是否正常 3、销毁故障： blade destroy <uid> | 1、故障制造成功，网络延迟生效 2、系统主流程验证时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                            | nan    | 如果--names不成功，使用--labels kubernetes.io/hostname= |

## 中间件

| 序号   | 故障类型    | 故障对象   | 用例名称                                                         | 执行步骤                                                                                                                                                                                                                                                                                                                                              | 预期结果                                                                                                                                                                                                                                         | 实际结果   | 备注   |
|:-----|:--------|:-------|:-------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------|:-----|
| 1    | MySQL故障 | 停服重启   | 模拟MySQL主备服务均不可用然后恢复，验证系统功能和MySQL相关读写功能正常                     | 1、缩容MySQL主备服务为0个pod，验证系统功能和MySQL相关读写功能是否正常 kubectl -n <namespace> scale sts <stsName> --replicas=0 2、扩容MySQL主备服务为3个pod，验证系统功能和MySQL相关读写功能是否正常 kubectl -n <namespace> scale sts <stsName> --replicas=3                                                                                                                                             | 1、缩容成功，读写功能均不可使用，但产品有友好提示 2、扩容成功，系统功能和MySQL相关读写功能正常                                                                                                                                                                                          | nan    | nan  |
| 2    | MySQL故障 | 主备切换   | 模拟MySQL发生主备切换，切换完成后，验证系统功能和MySQL相关读写功能正常                     | 1、删除MySQL主节点 kubectl -n <namespace> delete pod <主podName> 2、查看系统功能和MySQL相关的读写功能是否正常                                                                                                                                                                                                                                                               | 1、MySQL主节点删除成功 2、系统功能和MySQL相关的读写功能正常                                                                                                                                                                                                         | nan    | nan  |
| 3    | MySQL故障 | 连接数满   | 模拟MySQL连接数被打满，验证系统功能和MySQL相关读写功能正常                           | 1、使用JMeter工具高并发打满MySQL连接数 2、查看系统功能和MySQL相关的读写功能是否正常                                                                                                                                                                                                                                                                                               | 1、MySQL连接数被打满 show variables like 'max_connections';  --查看MySQL配置的最大连接数 show status like 'Threads_connected';  --查看实时连接数 2、已建立连接的用户：系统功能和MySQL相关的读写功能正常，新建立的连接有友好提示                                                                          | nan    | nan  |
| 4    | MySQL故障 | 网络延迟   | 模拟MySQL主备服务间网络延迟3秒，验证系统功能和MySQL相关读写功能正常                      | 1、使用chaosblade工具模拟MySQL主备服务间网络延迟3秒 blade create k8s container-network delay --names <主podName> --namespace <namespace> --container-names <containerName> --time 3000 --interface eth0 --destination-ip <备podIP> --timeout 3 --use-sidecar-container-network --kubeconfig /root/.kube/config 2、查看系统功能和MySQL相关的读写功能是否正常 3、销毁故障： blade destroy <uid> | 1、主备网络延迟生效 可以通过新增数据，分别进入主备pod中查询MySQL数据 2、系统功能和MySQL相关的读写功能正常 3、故障销毁成功                                                                                                                                                                       | nan    | nan  |
| 5    | MySQL故障 | cpu负载高 | 模拟MySQL主备服务cpu使用率90%，验证系统功能和MySQL相关读写功能正常                    | 1、使用chaosblade工具模拟MySQL主备服务cpu使用率90% blade create k8s container-cpu fullload --names <podName> --namespace <namespace> --container-names <containerName> --cpu-percent 90 --kubeconfig /root/.kube/config 2、验证系统功能和MySQL相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                                    | 1、故障制造成功，cpu负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep mysql 2、验证系统功能和MySQL相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                              | nan    | nan  |
| 6    | MySQL故障 | 内存负载高  | 模拟MySQL主备服务内存使用率90%，验证系统功能和MySQL相关读写功能正常                     | 1、使用chaosblade工具模拟MySQL主备服务cpu使用率90% blade create k8s container-mem load --names <podName> --namespace <namespace> --container-names <containerName>--mem-percent 90 --mode=ram --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和MySQL相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                | 1、故障制造成功，cpu负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep mysql 2、验证系统功能和MySQL相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                              | nan    | nan  |
| 7    | MySQL故障 | 杀node  | 手动重启MySQL主所在node节点                                           | 1、重启mysql所在node节点 2、验证系统功能和pgsql相关读写功能是否正常                                                                                                                                                                                                                                                                                                        | 1、node节点重启成功后，pod依然在该node节点正常启动 2、系统功能和MySQL相关的读写功能正常                                                                                                                                                                                        | nan    | nan  |
| 8    | PgSQL故障 | 停服重启   | 模拟PgSQL服务均不可用然后恢复，验证系统功能和pgsql相关读写功能正常                       | 1、缩容pgsql服务为0个pod，验证系统功能和pgsql相关读写功能是否正常 kubectl -n <namespace> scale sts <stsName> --replicas=0 2、1、缩容MySQL主备服务为1个pod，验证系统功能和pgsql相关读写功能是否正常 kubectl -n <namespace> scale sts <stsName> --replicas=1                                                                                                                                             | 1、缩容成功，读写功能均不可使用，但产品有友好提示 2、扩容成功，系统功能和pgsql相关读写功能正常                                                                                                                                                                                          | nan    | nan  |
| 9    | PgSQL故障 | 连接数满   | 模拟pgsql连接数被打满，验证系统功能和pgsql相关读写功能正常                           | 1、使用JMeter工具高并发打满pgsql连接数 2、查看系统功能和pgsql相关的读写功能是否正常                                                                                                                                                                                                                                                                                               | 1、pgsql连接数被打满 show max_connections;  --查看pgsql配置的最大连接数 select count(1) from pg_stat_activity;  --查看实时连接数 2、已建立连接的用户：系统功能和pgsql相关的读写功能正常，新建立的连接有友好提示                                                                                          | nan    | nan  |
| 10   | PgSQL故障 | cpu负载高 | 模拟pgsql服务cpu使用率90%，验证系统功能和pgsql相关读写功能正常                      | 1、使用chaosblade工具模拟pgsql服务cpu使用率90% blade create k8s container-cpu load --names <podName> --namespace <namespace> --container-names <containerName> --cpu-percent 90 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和pgsql相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                            | 1、故障制造成功，cpu负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep postgres 2、验证系统功能和pgsql相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                           | nan    | nan  |
| 11   | PgSQL故障 | 内存负载高  | 模拟pgsql服务内存使用率90%，验证系统功能和pgsql相关读写功能正常                       | 1、使用chaosblade工具模拟pgsql主备服务内存使用率90% blade create k8s container-mem load --names <podName> --namespace <namespace> --container-names <containerName>--mem-percent 90 --mode=ram --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和pgsql相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                 | 1、故障制造成功，内存负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep postgres 2、验证系统功能和pgsql相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                            | nan    | nan  |
| 12   | PgSQL故障 | 杀node  | 手动重启pgsql主所在node节点                                           | 1、重启pgsql所在node节点 2、验证系统功能和pgsql相关读写功能是否正常                                                                                                                                                                                                                                                                                                        | 1、node节点重启成功后，pod依然在该node节点正常启动 2、系统功能和pgsql相关的读写功能正常                                                                                                                                                                                        | nan    | nan  |
| 13   | Redis故障 | 停服重启   | 扩缩容redis副本，验证系统功能和redis相关读写功能正常                              | 1、缩容redis副本数量为0，验证系统功能和redis相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=0 2、扩容redis副本数量为3，验证系统功能和redis相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=3                                                                                                                                                                     | 1、副本缩为0，强依赖redis的读写功能均异常，弱依赖redis的读写功能可能慢一些但正常 2、系统功能和redis相关的读写功能正常                                                                                                                                                                         | nan    | nan  |
| 14   | Redis故障 | 重选主    | 重新选redis主后，验证系统功能和redis相关读写功能正常                              | 1、查询并删除redis主服务pod kubectl -n <namespace>  delete pod  <主podName> 2、验证系统功能和redis相关读写功能是否正常                                                                                                                                                                                                                                                        | 1、删除redis主pod后，自动触发选主，选主成功 查询master：kubectl -n <namespace> exec -it pod/redis-master-0 -- redis-cli  info Replication | grep role，结果：role:master  2、系统功能和redis相关的读写功能正常（如：项目流水线查询示例代码源）                                                      | nan    | nan  |
| 15   | Redis故障 | cpu负载高 | 模拟redis服务全pod的cpu使用率90%，验证系统功能和redis相关读写功能正常                 | 1、使用chaosblade工具模拟redis服务全pod的cpu使用率90% blade create k8s container-cpu fullload --names <podName1>,<podName2>  --namespace <namespace> --container-names <containerName> --cpu-percent 90 --timeout 600  --kubeconfig /root/.kube/config 2、验证系统功能和redis相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                     | 1、故障制造成功，cpu负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep redis 2、验证系统功能和redis相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                              | nan    | nan  |
| 16   | Redis故障 | 内存负载高  | 模拟redis服务全pod的内存使用率90%，验证系统功能和redis相关读写功能正常                  | 1、使用chaosblade工具模拟redis服务全pod的内存使用率90% blade create k8s container-mem load --names <podName1>,<podName2> --namespace <namespace> --container-names <containerName> --mem-percent 90 --timeout 600 --mode=ram --kubeconfig /root/.kube/config 2、验证系统功能和redis相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                 | 1、故障制造成功，内存负载高生效；可以使用top命令查看资源占用情况 kubectl top pod -n pub-comm |grep redis 2、验证系统功能和redis相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                               | nan    | nan  |
| 17   | Redis故障 | 杀pod   | 杀掉redis所有的slave pod，验证系统功能和redis相关读写功能正常                     | 1、删除redis的所有slave pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和redis相关读写功能是否正常                                                                                                                                                                                                                                                        | 1、pod删除成功，会自动重新构建并正常提供服务 查询master：kubectl -n <namespace> exec -it pod/redis-master-0 -- redis-cli  info Replication | grep role，结果：role:master  2、pod重启期间，redis不可用，强依赖redis的读写功能均异常，弱依赖redis的读写功能可能慢一些但正常，重启成功后，可正常提供服务                      | nan    | nan  |
| 18   | Redis故障 | 杀node  | 手动重启redis主所在node节点                                           | 1、重启redis主所在node节点 2、验证系统功能和redis相关读写功能是否正常                                                                                                                                                                                                                                                                                                       | 1、重启成功，自动发生redis选主，node节点重启成功后，pod依然在该node节点正常启动，但成为slave节点 查询master：kubectl -n <namespace> exec -it pod/redis-master-0 -- redis-cli  info Replication | grep role，结果：role:master  2、主备切换完成后，系统功能和redis相关的读写功能正常                             | nan    | nan  |
| 19   | Minio故障 | 停服重启   | 扩缩容minio副本，验证系统功能和minio相关读写功能正常                              | 1、缩容minio副本数量为0，验证系统功能和minio相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=0 2、扩容minio副本数量为4，验证系统功能和minio相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=4                                                                                                                                                                     | 1、副本缩为0，强依赖minio的读写功能均异常，弱依赖minio的读写功能可能慢一些但正常 2、系统功能和minio相关的读写功能正常                                                                                                                                                                         | nan    | nan  |
| 20   | Minio故障 | 磁盘负载高  | 模拟minio服务所在磁盘容量使用率90%，验证系统功能和minio相关读写功能正常                   | 1、使用chaosblade工具minio服务所在磁盘容量使用率90% blade create disk fill --path /data/nfs-fileshare --percent 90 --timeout 600 2、验证系统功能和minio相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                                                                                                                             | 1、故障制造成功，磁盘负载高生效；可以使用df命令查看资源占用情况 2、验证系统功能和minio相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                                                                        | nan    | nan  |
| 21   | Minio故障 | 磁盘满    | 模拟minio服务所在磁盘容量满然后恢复，验证系统功能和minio相关读写功能正常                    | 1、使用chaosblade工具minio服务所在磁盘使用满，验证系统功能和minio相关读写功能正常 blade create disk fill --path /data/nfs-fileshare --size <disk_size> --timeout 300 2、销毁磁盘满故障，验证系统功能和minio相关读写功能正常 blade destroy <uid>                                                                                                                                                         | 1、故障制造成功，磁盘被打满，系统功能和minio相关的读功能不受影响，写功能失败； 可以使用df命令查看资源占用情况 2、故障销毁成功，系统功能和minio相关的读写功能均正常                                                                                                                                                    | nan    | nan  |
| 22   | Minio故障 | cpu负载高 | 模拟minio服务全pod的cpu使用率90%，验证系统功能和minio相关读写功能正常                 | 1、使用chaosblade工具模拟minio服务全pod的cpu使用率90% blade createreate k8s pod-cpu load --names <podName1>,<podName2>  --namespace <namespace> --cpu-percent 90 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和minio相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                                             | 1、故障制造成功，cpu负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和minio相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                                | nan    | nan  |
| 23   | Minio故障 | 内存负载高  | 模拟minio服务全pod的内存使用率90%，验证系统功能和minio相关读写功能正常                  | 1、使用chaosblade工具模拟minio服务全pod的内存使用率90% blade createreate k8s pod-mem load --names <podName1>,<podName2> --namespace <namespace> --mem-percent 90  --mode=ram --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和minio相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                                                   | 1、故障制造成功，内存负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和minio相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                                 | nan    | nan  |
| 24   | Minio故障 | 杀pod   | 随机杀掉一个minio的 pod，验证系统功能和minio相关读写功能正常                        | 1、随机杀掉一个minio的pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和minio相关读写功能是否正常                                                                                                                                                                                                                                                            | 1、pod删除成功，会自动重新构建并正常提供服务 2、系统功能和minio相关的读写功能正常                                                                                                                                                                                               | nan    | nan  |
| 25   | Minio故障 | 杀node  | 随机重启一个minio的pod所在node节点，验证系统功能和minio相关读写功能正常                 | 1、随机重启一个minio的所在node节点服务器 2、验证系统功能和minio相关读写功能是否正常                                                                                                                                                                                                                                                                                                | 1、pod删除成功，会自动重新构建并正常提供服务 2、系统功能和minio相关的读写功能正常                                                                                                                                                                                               | nan    | nan  |
| 26   | ZK故障    | 停服重启   | 扩缩容zk副本，验证系统功能和zookeeper相关读写功能正常                             | 1、缩容zookeeper副本数量为0，验证系统功能和zookeeper相关读写功能正常 kubectl -n <namespace> sts  <stsName> --replicas=0 2、扩容zookeeper副本数量为3，验证系统功能和zookeeper相关读写功能正常 kubectl -n <namespace> sts  <stsName>  --replicas=3                                                                                                                                                  | 1、副本缩为0，系统功能和zookeeper相关的读写功能正常 2、系统功能和zookeeper相关的读写功能正常                                                                                                                                                                                    | nan    | nan  |
| 27   | ZK故障    | 重选主    | 重新选zk主后，验证系统功能和zookeeper相关读写功能正常                             | 1、查询并删除zk主服务pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和zookeeper相关读写功能是否正常                                                                                                                                                                                                                                                          | 1、删除zk主pod后，自动触发选主，选主成功 查看zookeeper-leader节点：kubectl -n <namespace> exec -it <zkPodName> -- bash -c 'zkServer.sh status' 2、系统功能和zookeeper相关的读写功能正常（zk只负责zookeeper的选主、调度等）                                                                    | nan    | nan  |
| 28   | ZK故障    | cpu负载高 | 模拟zk服务全pod的cpu使用率90%，验证系统功能和zookeeper相关读写功能正常                | 1、使用chaosblade工具模拟zk服务全pod的cpu使用率90% blade create k8s container-cpu load --names <podName1>,<podName2>,<podName3> --namespace <namespace> --container-names zookeeper --cpu-percent 90 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和zookeeper相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                     | 1、故障制造成功，cpu负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和zookeeper相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                            | nan    | nan  |
| 29   | ZK故障    | 内存负载高  | 模拟zk服务全pod的内存使用率90%，验证系统功能和zookeeper相关读写功能正常                 | 1、使用chaosblade工具模拟zk服务全pod的内存使用率90% blade create k8s container-mem load --names zookeeper-0,zookeeper-1,zookeeper-2 --namespace <namespace> --container-names zookeeper --mem-percent 90 --timeout 600 --mode=ram --kubeconfig /root/.kube/config 2、验证系统功能和zookeeper相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                        | 1、故障制造成功，内存负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和zookeeper相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                             | nan    | nan  |
| 30   | ZK故障    | 杀pod   | 杀掉zk所有的slave pod，验证系统功能和zookeeper相关读写功能正常                    | 1、删除zk的所有slave pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和zookeeper相关读写功能是否正常                                                                                                                                                                                                                                                       | 1、pod删除成功，会自动重新构建并正常提供服务 2、系统功能和zookeeper相关的读写功能正常                                                                                                                                                                                           | nan    | nan  |
| 31   | ZK故障    | 杀node  | 重启zk主所在node节点，验证系统功能和zookeeper相关读写功能正常                       | 1、查询并重启zk主pod所在node节点服务器 2、验证系统功能和zookeeper相关读写功能是否正常                                                                                                                                                                                                                                                                                             | 1、zookeeper主会进行重新选举，并等待该node节点启动，然后依然在该节点启动pod 查看zookeeper-leader节点：kubectl -n <namespace> exec -it <zookeeper-pod名字> -- bash -c 'zkServer、sh status' 删除pod：kubectl -n <namespace> delete pod <zookeeper-leader节点> 2、系统功能和zookeeper相关的读写功能正常 | nan    | nan  |
| 32   | Kafka故障 | 停服重启   | 扩缩容zk副本，验证系统功能和kafka相关读写功能正常                                 | 1、缩容kafka副本数量为0，验证系统功能和kafka相关读写功能正常 kubectl -n <namespace> sts  <stsName> --replicas=0 2、扩容kafka副本数量为3，验证系统功能和kafka相关读写功能正常 kubectl -n <namespace> sts  <stsName>  --replicas=3                                                                                                                                                                  | 1、副本缩为0，系统功能和kafka相关的读写功能正常 2、系统功能和kafka相关的读写功能正常                                                                                                                                                                                            | nan    | nan  |
| 33   | Kafka故障 | 重选主    | 重新选zk主后，验证系统功能和kafka相关读写功能正常                                 | 1、查询并删除zk主服务pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和kafka相关读写功能是否正常                                                                                                                                                                                                                                                              | 1、删除zk主pod后，自动触发选主，选主成功 查看kafka-leader节点：kubectl -n <namespace> exec -it <zkPodName> -- bash -c 'zkServer.sh status' 2、系统功能和kafka相关的读写功能正常（zk只负责kafka的选主、调度等）                                                                                | nan    | nan  |
| 34   | Kafka故障 | cpu负载高 | 模拟zk服务全pod的cpu使用率90%，验证系统功能和kafka相关读写功能正常                    | 1、使用chaosblade工具模拟zk服务全pod的cpu使用率90% blade create k8s container-cpu load --names <podName1>,<podName2>,<podName3> --namespace <namespace> --container-names kafka --cpu-percent 90 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和kafka相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                             | 1、故障制造成功，cpu负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和kafka相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                                | nan    | nan  |
| 35   | Kafka故障 | 内存负载高  | 模拟zk服务全pod的内存使用率90%，验证系统功能和kafka相关读写功能正常                     | 1、使用chaosblade工具模拟zk服务全pod的内存使用率90% blade create k8s container-mem load --names kafka-0,kafka-1,kafka-2 --namespace <namespace> --container-names kafka --mem-percent 90 --timeout 600 --mode=ram --kubeconfig /root/.kube/config 2、验证系统功能和kafka相关读写功能是否正常 3、销毁故障： blade destroy <uid>                                                            | 1、故障制造成功，内存负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和kafka相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                                 | nan    | nan  |
| 36   | Kafka故障 | 杀pod   | 杀掉zk所有的slave pod，验证系统功能和kafka相关读写功能正常                        | 1、删除zk的所有slave pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和kafka相关读写功能是否正常                                                                                                                                                                                                                                                           | 1、pod删除成功，会自动重新构建并正常提供服务 2、系统功能和kafka相关的读写功能正常                                                                                                                                                                                               | nan    | nan  |
| 37   | Kafka故障 | 杀node  | 重启zk主所在node节点，验证系统功能和kafka相关读写功能正常                           | 1、查询并重启zk主pod所在node节点服务器 2、验证系统功能和kafka相关读写功能是否正常                                                                                                                                                                                                                                                                                                 | 1、kafka主会进行重新选举，并等待该node节点启动，然后依然在该节点启动pod 查看kafka-leader节点：kubectl -n <namespace> exec -it <kafka-pod名字> -- bash -c 'zkServer、sh status' 删除pod：kubectl -n <namespace> delete pod <kafka-leader节点> 2、系统功能和kafka相关的读写功能正常                     | nan    | nan  |
| 38   | ES故障    | 停服重启   | 扩缩容elasticsearch副本，验证系统功能和elasticsearch相关读写功能正常              | 1、缩容elasticsearch副本数量为0，验证系统功能和elasticsearch相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=0 2、扩容elasticsearch副本数量为3，验证系统功能和elasticsearch相关读写功能正常 kubectl -n <namespace> sts <stsName> --replicas=3                                                                                                                                     | 1、副本缩为0，强依赖elasticsearch的读写功能均异常，弱依赖elasticsearch的读写功能可能慢一些但正常 2、系统功能和elasticsearch相关的读写功能正常                                                                                                                                                 | nan    | nan  |
| 39   | ES故障    | 重选主    | 重新选elasticsearch主后，验证系统功能和elasticsearch相关读写功能正常              | 1、查询并删除elasticsearch主服务pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和elasticsearch相关读写功能是否正常                                                                                                                                                                                                                                           | 1、删除elasticsearch主pod后，自动触发选主，选主成功 查询master：kubectl -n <namespace> exec -it <podName>  -- bash -c 'curl localhost:9200/_cat/master?v' 2、系统功能和elasticsearch相关的读写功能正常                                                                          | nan    | nan  |
| 40   | ES故障    | cpu负载高 | 模拟elasticsearch服务全pod的cpu使用率90%，验证系统功能和elasticsearch相关读写功能正常 | 1、使用chaosblade工具模拟elasticsearch服务全pod的cpu使用率90% blade create k8s container-cpu load --names <podName1>,<podName2>,<podName3> --namespace <namespace> --container-names kafka --cpu-percent 90 --timeout 600 --kubeconfig /root/.kube/config 2、验证系统功能和elasticsearch相关读写功能是否正常 3.销毁故障： blade destroy <uid>                                          | 1、故障制造成功，cpu负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和elasticsearch相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                        | nan    | nan  |
| 41   | ES故障    | 内存负载高  | 模拟elasticsearch服务全pod的内存使用率90%，验证系统功能和elasticsearch相关读写功能正常  | 1、使用chaosblade工具模拟elasticsearch服务全pod的内存使用率90% blade create k8s container-mem load --names kafka-0,kafka-1,kafka-2 --namespace <namespace> --container-names kafka --mem-percent 90 --timeout 600 --mode=ram --kubeconfig /root/.kube/config 2、验证系统功能和elasticsearch相关读写功能是否正常 3.销毁故障： blade destroy <uid>                                         | 1、故障制造成功，cpu负载高生效； 可以使用kubectl -n <namespace> top pod <podName>命令查看资源占用情况 2、验证系统功能和elasticsearch相关功能时，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功                                                                                                        | nan    | nan  |
| 42   | ES故障    | 杀pod   | 杀掉elasticsearch所有的slave pod，验证系统功能和elasticsearch相关读写功能正常     | 1、删除redis的所有slave pod kubectl -n <namespace> delete pod <podName> 2、验证系统功能和elasticsearch相关读写功能是否正常                                                                                                                                                                                                                                                | 1、pod删除成功，会自动重新构建并正常提供服务 查询master：kubectl -n <namespace> exec -it <elasticsearch-PodName>  -- bash -c 'curl localhost:9200/_cat/master?v' 2、pod重启期间，elasticsearch不可用，强依赖elasticsearch的读写功能均异常，弱依赖elasticsearch的读写功能可能慢一些但正常，重启成功后，可正常提供服务    | nan    | nan  |
| 43   | ES故障    | 杀node  | 手动重启elasticsearch主所在node节点                                   | 1、重启elasticsearch主所在node节点 2、验证系统功能和elasticsearch相关读写功能是否正常                                                                                                                                                                                                                                                                                       | 1、重启成功，自动发生elasticsearch选主，node节点重启成功后，pod依然在该node节点正常启动，但成为slave节点 查询master：kubectl -n <namespace> exec -it <elasticsearch-PodName>  -- bash -c 'curl localhost:9200/_cat/master?v' 2、主备切换完成后，系统功能和elasticsearch相关的读写功能正常                   | nan    | nan  |

## 业务应用

| 序号   | 故障类型    | 故障对象   | 用例名称                                | 执行步骤                                                                                                                                                                                                                                                   | 预期结果                                                                                                          | 实际结果   | 备注   |
|:-----|:--------|:-------|:------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------|:-------|:-----|
| 1    | 副本异常    | pod    | <serviceName>的一个副本重启后，对业务无影响        | 1、删除<serviceName>的pod01： kubectl delete pod <podName> -n <namespace> 2、pod重启之后，检查系统功能                                                                                                                                                                  | 1、被删除的pod可以正常启动 2、系统功能正常                                                                                      | nan    | nan  |
| 2    | 服务扩缩容验证 | pod    | <serviceName>的pod进行扩缩容，对业务无影响       | 1、扩容<serviceName>的pod数量为5个： kubectl scale deploy praefect --replicas=5 2、扩容期间：检查系统功能 3、缩容<serviceName>的pod数量为1个： kubectl scale deploy webunicorn --replicas=1 4、缩容期间：检查系统功能                                                                            | 1、扩容成功，pod数量正确且运行正常 2、系统功能正常 3、缩容成功，pod数量正确且运行正常 4、系统功能正常                                                     | nan    | nan  |
| 3    | cpu负载高  | pod    | 模拟<serviceName>pod cpu使用率90%，对业务无影响 | 1、使用chaosblade工具模拟<serviceName>所有服务cpu使用率90% blade create k8s container-cpu fullload --names <podName> --namespace <namespace> --container-names <containerName> --cpu-percent 90 --kubeconfig /root/.kube/config 2、检查系统功能 3、销毁故障： blade destroy <uid> | 1、故障制造成功，cpu负载高生效； kubectl top pod -n gitee-prod |grep <serviceName> 2、系统功能正常，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功 | nan    | nan  |
| 4    | 内存负载高   | pod    | 模拟<serviceName>pod 内存使用率90%，对业务无影响  | 1、使用chaosblade工具模拟<serviceName>所有服务内存使用率90% blade create k8s container-mem load --names <podName> --namespace <namespace> --container-names <containerName> --cpu-percent 90 --kubeconfig /root/.kube/config 2、检查系统功能 3、销毁故障： blade destroy <uid>      | 1、故障制造成功，内存负载高生效； kubectl top pod -n gitee-prod |grep <serviceName> 2、系统功能正常，系统使用体验上可能会慢一些，但整体功能无异常 3、故障销毁成功  | nan    | nan  |
| 5    | 亲和性验证   | pod    | 检查<serviceName>亲和性设置是否符合要求          | 1、编辑<serviceName>，查看pod的亲和性设置 kubectl edit pod <podName> -n gitee-prod 2、删除1个pod等待重启后查看pod在node节点的部署情况 kubectl get pod -n gitee-prod -o wide|grep <serviceName>                                                                                        | 1、pod的亲和性设置，包含podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution 2、pod01、pod02不在同一个node         | nan    | nan  |

